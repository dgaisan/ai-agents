{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHuuibfLIl2BSxNOzR9DmP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgaisan/ai-agents/blob/main/CrewAI-based-Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running Agents using Ollama and CrewAI**"
      ],
      "metadata": {
        "id": "3TeK53Sjw_Ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Environment Setup\n"
      ],
      "metadata": {
        "id": "mm9P5cskw9aU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs ollama dependency"
      ],
      "metadata": {
        "id": "qNaAgpleWe2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ollama\n",
        "%pip install colab-xterm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tpB29zRpxgLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs utilities for checking CPU/GPU avail"
      ],
      "metadata": {
        "id": "EjqR-E_Lxwl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install pciutils lshw"
      ],
      "metadata": {
        "id": "tcdDhMNFxyQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads and installs Ollama via the official shell script (Run only once)"
      ],
      "metadata": {
        "id": "w2Vn7S9Nx5sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "kO3457BnyAXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pulling Deepseek & llama Models"
      ],
      "metadata": {
        "id": "QxTBXaTL0AJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the deepseek-r1:7b\n",
        "!ollama pull deepseek-r1:7b\n",
        "# Download the llama3\n",
        "!ollama pull llama3"
      ],
      "metadata": {
        "id": "hGESCz_L0GA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pulling Lightweight SLMs"
      ],
      "metadata": {
        "id": "Fjtd6Ufe0QWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ultra-small general models\n",
        "!ollama pull phi3:mini\n",
        "!ollama pull tinyllama\n",
        "# Google's compact chat model\n",
        "!ollama pull gemma:2b\n",
        "# reasoning model\n",
        "!ollama pull deepseek-r1:1.5b"
      ],
      "metadata": {
        "id": "9zrIF4tC0fCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Installed Models"
      ],
      "metadata": {
        "id": "bo-owF4n1kiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "id": "nZ9H6diZ1lU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Launching Ollama server"
      ],
      "metadata": {
        "id": "4oqux9jVXI_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports libs for managing HTTP requests, subprocesses, and multithreading"
      ],
      "metadata": {
        "id": "eOHLOp3CXYsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import subprocess\n",
        "import threading\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "o9CQQinQXP27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launches Ollama server in the background"
      ],
      "metadata": {
        "id": "59CA66BnXwSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spin up Ollama Server\n",
        "def run_ollama():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "thread = threading.Thread(target=run_ollama)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "puQ3TNEuYD3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests if the server is running"
      ],
      "metadata": {
        "id": "oYXqUaKZYNNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://127.0.0.1:11434"
      ],
      "metadata": {
        "id": "RBP7ce--YTFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silences some warning (optional)"
      ],
      "metadata": {
        "id": "FUWuA138Yixr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# avoids restart session warning in Colab\n",
        "# import sys\n",
        "# sys.modules.pop('PIL', None)"
      ],
      "metadata": {
        "id": "ry93axW9Ympx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: CrewAI integration"
      ],
      "metadata": {
        "id": "UFD3cVuSY21j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents are defined using CrewAI.\n",
        "Enables multi-agent workflows.\n",
        "Agents are connected to Ollama server"
      ],
      "metadata": {
        "id": "mXzJJmG0Y6HI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs CrewAI libs/tools"
      ],
      "metadata": {
        "id": "8nTKCoAzZSB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/joaomdmoura/crewAI.git --quiet\n",
        "%pip install crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere --quiet\n",
        "print(\"---\")\n",
        "%pip show crewAI crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere\n",
        "%pip install -qU langchain-ollama"
      ],
      "metadata": {
        "id": "cz0TBGZVZgG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent imports dependencies"
      ],
      "metadata": {
        "id": "phVzOYn6Zq7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "from getpass import getpass\n",
        "from langchain_ollama import ChatOllama\n",
        "from textwrap import dedent\n",
        "import os"
      ],
      "metadata": {
        "id": "8taL0991ZziN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Agents with CrewAI"
      ],
      "metadata": {
        "id": "2nXS58Eea1Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "from textwrap import dedent\n",
        "from langchain_ollama import ChatOllama\n",
        "from crewai import LLM\n",
        "\n",
        "MODEL_NAME = \"ollama/tinyllama:latest\"\n",
        "OLLAMA_ENDPOINT = \"http://127.0.0.1:11434\"\n",
        "\n",
        "llm = LLM(model=MODEL_NAME, base_url=OLLAMA_ENDPOINT)\n",
        "\n",
        "# Agent 1: Cloud Infrastructure Planner\n",
        "# Generates infrastructure plans (e.g., recommends services, architectures, scalability strategies)\n",
        "agent_1 = Agent(\n",
        "    role=dedent(\"\"\"Cloud Infrastructure Planner\"\"\"),\n",
        "    goal=dedent(\"\"\"Design efficient, scalable, and reliable cloud infrastructure based on project requirements.\"\"\"),\n",
        "    backstory=dedent(\"\"\"You are a cloud architecture expert with deep knowledge of AWS, Azure, and other major platforms. You excel at designing robust, cost-effective infrastructure tailored to technical and business needs.\"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=3,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Agent 2: Security Auditor\n",
        "# Reviews plans/configs to find risks, misconfigurations, compliance gaps\n",
        "agent_2 = Agent(\n",
        "    role=dedent(\"\"\"Security Auditor\"\"\"),\n",
        "    goal=dedent(\"\"\"Assess cloud infrastructure designs and configurations to identify potential security risks and recommend improvements.\"\"\"),\n",
        "    backstory=dedent(\"\"\"You are a cybersecurity specialist focused on cloud environments. Your expertise lies in spotting vulnerabilities, enforcing best practices, and ensuring systems are secure by design.\"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=3,\n",
        "    llm=llm\n",
        ")\n"
      ],
      "metadata": {
        "id": "KAOZlRmFa-X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Tasks for Agents (This is what Agents will be trying to achieve)"
      ],
      "metadata": {
        "id": "2JoyzgzQbdsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "from textwrap import dedent\n",
        "\n",
        "# Task for Cloud Infrastructure Planner\n",
        "task_1 = Task(\n",
        "    description=dedent(\"\"\"\n",
        "        Design a scalable, cost-efficient cloud infrastructure for a web application that expects moderate traffic (~10,000 daily active users) with occasional traffic spikes. The application requires high availability, data storage, and basic monitoring.\n",
        "    \"\"\"),\n",
        "    expected_output=dedent(\"\"\"\n",
        "        A high-level infrastructure plan (~200 words) that includes:\n",
        "        - Recommended cloud provider and reasoning\n",
        "        - Core services to be used (e.g., compute, storage, load balancing)\n",
        "        - Scalability and high availability considerations\n",
        "        - Optional: Cost optimization suggestions\n",
        "    \"\"\"),\n",
        "    agent=agent_1,\n",
        ")\n",
        "\n",
        "# Task for Security Auditor\n",
        "task_2 = Task(\n",
        "    description=dedent(\"\"\"\n",
        "        Review the proposed cloud infrastructure for the web application and identify potential security risks. Focus on aspects like data protection, access control, and network security. Suggest practical improvements or mitigations.\n",
        "    \"\"\"),\n",
        "    expected_output=dedent(\"\"\"\n",
        "        A concise security audit (~200 words) that covers:\n",
        "        - Key security risks or gaps in the proposed design\n",
        "        - Recommended security best practices for the identified risks\n",
        "        - Optional: Notes on compliance considerations (e.g., GDPR, SOC 2)\n",
        "    \"\"\"),\n",
        "    agent=agent_2,\n",
        "    context=[task_1],\n",
        ")"
      ],
      "metadata": {
        "id": "oq12JjIydYcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-------------------------------------------')\n",
        "\n",
        "topic_input = input(\"üîç Enter the Topic to explore\\n\")\n",
        "format_input = input(\"üß† What output format are you intersted in (e.g., article, summary)?\\n\")\n",
        "\n",
        "print('-------------------------------------------')\n",
        "print(f\"‚úîÔ∏è Topic Input: {topic_input}\\nFormat: {format_input}\\n\")\n"
      ],
      "metadata": {
        "id": "6SeD1bUlfDI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kicks in CrewAI work"
      ],
      "metadata": {
        "id": "MKV9TCcsf2xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    crew = Crew(\n",
        "        agents=[agent_1, agent_2],\n",
        "        tasks=[task_1, task_2],\n",
        "        verbose=True,\n",
        "        process=Process.sequential, # (e.g., sequential, hierarchical)\n",
        "        planning_llm=llm\n",
        "    )\n",
        "\n",
        "    inputs = {\n",
        "    \"topic\": topic_input,\n",
        "    \"format\": format_input\n",
        "    }\n",
        "\n",
        "    result = crew.kickoff(inputs=inputs)\n",
        "    print(\"\\n\\n-----------------------------------\")\n",
        "    print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  result = main()"
      ],
      "metadata": {
        "id": "y_5WAMPVf52v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "markdown_text = result.raw  # Adjust this based on the actual attribute\n",
        "\n",
        "display(Markdown(markdown_text))"
      ],
      "metadata": {
        "id": "__u56C5zga0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}